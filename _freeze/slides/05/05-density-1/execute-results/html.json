{
  "hash": "bc76ea75769b4d0f02f48cdcc2dc6f91",
  "result": {
    "markdown": "---\ntitle: Visualizing density - I\nsubtitle: Lecture 5\ntitle-slide-attributes:\n  data-background-image: ../vizdata-bg.png\n  data-background-size: 800px, cover\n  data-slide-number: none\nformat: revealjs\nhighlight-style: a11y\nexecute:\n  code-link: true\neditor_options:\n  chunk_output_type: console\nrevealjs-plugins:\n  - code-mover\n---\n\n\n## Announcements\n\n-   Office Hours Monday will be devoted to Project 1!\n-   Project 1 proposals submitted for peer review by 11am Monday, Feb 5th\n-   Project proposal peer review\n    -   You'll be assessed on the quality (and participation) of your peer review\n\n    -   Updates based on peer review are due Monday, Feb 5th at 11:59pm\n\n    -   Full group attendance is **mandatory**\n\n    -   Your proposal will be \"graded\" after that, by me\n\n\n::: {.cell}\n\n:::\n\n\n## Distributions {.smaller}\n\nThere are many properties of a distribution of values\n\n-   **Center**: Mean, Median, Modes\n-   **Spread**: Variance, Range (Support), Interquartile range\n-   **Shape**: Skewness, Kurtosis, Quantiles\n-   Any statistic you can think of\n\n. . .\n\nUltimately when analyzing data, the distribution is important to know how to proceed:\n\n-   Parametric tests\n-   Erratic Data\n-   Outliers\n\nSo let's visualize them!\n\n## Histograms {.smaller fig-align=\"center\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nHistogram of 200 random numbers generated from a $\\textsf{Normal}(\\mu=-1, \\sigma=0.5)$ and 400 generated from a $\\textsf{Normal}(\\mu=2, \\sigma=0.75)$:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/histogram-example-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n## Density Plots {.smaller}\n\n**What's the difference?** Histograms are *counts* of bins of *observed* data. Density plots are *estimates* of the *unknown* distribution.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/density-example-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n## So what? {.smaller .no-list-margins}\n\n::: {.no-list-margins style=\"font-size:0.75em;\"}\n-   Histograms are sensitive to where the bins are cut\n\n-   Histograms vary more per random sample than density plots\n\n-   Density graphs are estimates for what a very fine histogram with lots of data would show\n:::\n\n. . .\n\n\n```{ojs}\n//| echo: false\n//| panel: sidebar\n\nviewof binWidth = Inputs.range([0.01, 1.5], {value: 0.2, step: 0.001, label: \"Bin Width\"});\nviewof numPoints = Inputs.range([0, 9000], {value: 900, step: 1, label: \"Number of Points\"});\nviewof generate = Inputs.button(\"Regenerate Data\");\n```\n\n```{ojs}\n//| echo: false\n//| panel: fill\n\nimport { plotNewData, regenerateData } from \"./histoSampling.js\";\n\n// Generate does not actually get used just forces a refresh\nplotNewData(regenerateData(numPoints / 3), binWidth, generate);\n```\n\n\n::: footer\nBased on [example](https://observablehq.com/@d3/kernel-density-estimation) by Mike Bostock\n:::\n\n## Motivating Example\n\n::: smallest\n-   Baseball! A home run in baseball occurs when a player hits a fair ball outside of the playing field. Examples:\n\n::: {style=\"text-align: center\"}\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/CiDy3-EsXiM\">\n\n</iframe>\n:::\n:::\n\n. . .\n\n::: smallest\n-   Home runs are exciting! Baseball currently has a marketing problem, but throughout history Major League Baseball (MLB, the organization running the highest level of professional baseball) has tried to change the rules to increase home runs to help the game be more entertaining.\n\n    -   In short terms, **Home runs = Money**, but if everyone hits the same number of home runs they become less exciting.\n    -   Examining the distribution of home runs year-by-year we may be able to see the effect of rule changes.\n:::\n\n## Data\n\n::: smallest\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(Lahman)\nnames(Batting)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"playerID\" \"yearID\"   \"stint\"    \"teamID\"   \"lgID\"     \"G\"       \n [7] \"AB\"       \"R\"        \"H\"        \"X2B\"      \"X3B\"      \"HR\"      \n[13] \"RBI\"      \"SB\"       \"CS\"       \"BB\"       \"SO\"       \"IBB\"     \n[19] \"HBP\"      \"SH\"       \"SF\"       \"GIDP\"    \n```\n:::\n:::\n\n\nOur dataset comes from the R package `Lahman`. Each row in the data frame is the hitting stats of a player for a given year. We will mostly be using the following columns:\n\n| Variable   | Description                                                                        |\n|--------------|----------------------------------------------------------|\n| `yearID`   | The year for the statistics                                                        |\n| `playerID` | Player unique ID to distinguish rows                                               |\n| `HR`       | The number of home runs a player hit in a given year                               |\n| `SB`       | Stolen bases; more stolen bases = faster player                                    |\n| `G`        | Number of games played; there are 162 games in a baseball season (154 before 1961) |\n| `BB`       | Walks; more walks = defense is worried about player hitting home runs              |\n| `SO`       | Strike outs; more strikeouts = Hitter is swinging recklessly                       |\n:::\n\n## Data we will use {auto-animate=\"true\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs <- Batting\n```\n:::\n\n\nWe are interested in the distribution of the number of home runs individual players have hit per year. [^1]\n\n[^1]: The record for number of home runs in one year is 73, by Barry Bonds in 2001. The 73rd home run baseball was sold for **\\$517,000**!\n\n## Context 1 {auto-animate=\"true\"}\n\nThere are many players in the dataset that played very little games per year, so we will limit to players that played at least 100 games in a given year, with the following years excepted:\n\n-   In 1994 only about 115 games were played due to labor strikes, so will filter to at least 70 games.\n-   In 2020 COVID shortened the season to only 60 games, so we will filter at least 40 games.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994)\n  )\n```\n:::\n\n\n## Context 2 {auto-animate=\"true\"}\n\n-   We are only concerned with years after 1920 (known as the \"live-ball era\").\n-   Very few home runs were hit before 1920 as the same baseball was used for the entire game. About 100 baseballs are used every game today!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994),\n    yearID > 1920\n  )\n```\n:::\n\n\n## Context 3 {auto-animate=\"true\"}\n\nWe are only considering the `AL` and `NL` leagues as they have the best stat-tracking and are the only Major leagues still around today.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs <- Batting |>\n  filter(\n    G >= 100 |\n    (G >= 40 & yearID == 2020) |\n    (G >= 70 & yearID == 1994),\n    yearID > 1920,\n    lgID %in% c(\"AL\", \"NL\")\n  )\n```\n:::\n\n\n## Density Graph Example {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/basic-geom-density-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: r-fit-text\n-   Most players hit just a few home runs per year and the distribution is very right-skewed.\n-   Very few players hit more than 40 per year.\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(home_runs, aes(HR)) +\n  geom_density() + \n  xlab(\"Home runs per player per year\")\n```\n:::\n\n:::\n\n## Stacked Density Graph By Decade {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/stacked-geom-density-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: r-fit-text\nIf we stratify by decade, we can see the **mode** of the density graphs slowly creep forward, but it is difficult to see the tail of the distribution.\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(HR, fill = decade)) +\n  geom_density(position = \"stack\") +\n  labs(x = \"Home runs per player per year\")\n```\n:::\n\n:::\n\n## Overlapping Density Graphs By Decade {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/overlapping-geom-density-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: r-fit-text\nThe modes moving forward is a little more apparent now, but the graphs are too coupled to digest easily.\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(HR, color = decade)) +\n  geom_density() +\n  labs(x = \"Home runs per player per year\")\n```\n:::\n\n:::\n\n## Density Graph with Conditional Probabilities {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/conditional-geom-density-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: {.small style=\"margin: 0\"}\nBy using `position = \"fill\"` and `y = after_stat(count)` we graph the conditional probability of a decade given that a player has hit a certain number of home runs. We see that players would hit about 60 homeruns in the 20's and 30's, but that disappears until the 90's and 2000's. [^2]\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  mutate(\n    decade = cut(\n      yearID,\n      breaks = seq(1920, 2030, 10),\n      labels = paste0(seq(1920, 2020, 10), \"'s\")\n    )\n  ) |>\n  ggplot(aes(x = HR, y = after_stat(count), fill = decade)) +\n  geom_density(position = \"fill\") +\n  geom_vline(xintercept = 60, linetype = \"dashed\") +\n  labs(x = \"Home runs per player per year\")\n```\n:::\n\n:::\n\n[^2]: With the exception of 1961, the year Roger Maris hit 61 home runs.\n\n## Violin Plot {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/violin-plot-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: r-fit-text\nLet's examine the years near the change point, 1985 to 2005. All points shown are players that hit 30 or more home runs in a given year. It looks like around 1995 players started hitting **a lot** more home runs.\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  filter(yearID %in% 1985:2005) |>\n  ggplot(aes(HR, x = factor(yearID))) +\n  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +\n  geom_jitter(\n    data = ~ filter(.x, HR >= 30),\n    height = 0, width = 0.1, alpha = 0.5\n  ) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  labs(x = \"Home runs per player per year\")\n```\n:::\n\n:::\n\n## Ridge Plot {.smaller}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/ridge-plot-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n::: {.small style=\"margin: 0\"}\nThe quantiles also have a consistent increase, along with many more players hitting 30 or more home runs! In 1998 there was a home run record race between two players; this brought a lot of interest back into baseball. 1995 to about 2005 is known as the *Steroid Era* in baseball. During this time, players would take performance enhancing drugs freely as the league did not enforce the ban on them. League-wide testing began in 2003.\n:::\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggridges)\n\nhome_runs |>\n  filter(yearID %in% 1985:2010) |>\n  ggplot(aes(x = HR, y = factor(yearID))) +\n  stat_density_ridges(\n    mapping = aes(fill = factor(after_stat(quantile))),\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(.25, .50, .75, .95),\n    quantile_lines = TRUE,\n    scale = 2,\n    rel_min_height = 0.01\n  ) +\n  scale_fill_viridis_d(\n    name = \"Quantiles\",\n    labels = c(\"0\", \"25th\", \"50th\", \"75th\", \"95th\")\n  ) +\n  geom_jitter(\n    data = ~ filter(.x, HR >= 30),\n    height = 0.2, width = 0, alpha = 0.3,\n  ) +\n  scale_x_continuous(\n    name = \"Home runs per player per year\",\n    limits = c(0, 73)\n  ) +\n  labs(y = \"Year\")\n```\n:::\n\n:::\n\n## Bandwidth {.smaller}\n\nDensity graphs are sensitive to **bandwidth**, but this is a continuous degradation of performance.\n\n\n```{ojs}\n//| echo: false\n//| panel: sidebar\n\nviewof binWidth2 = Inputs.range([0.01, 1.5], {value: 0.2, step: 0.001, label: \"Bin Width\"});\nviewof bandwidth = Inputs.range([0.01, 2], {value: 0.2, step: 0.001, label: \"Bandwidth\"});\nviewof numPoints2 = Inputs.range([0, 9000], {value: 900, step: 1, label: \"Number of Points\"});\nviewof generate2 = Inputs.button(\"Regenerate Data\");\n```\n\n```{ojs}\n//| echo: false\n//| panel: fill\nimport { plotNewDataBW } from \"./bandwidthSampling.js\";\n\n// Generate does not actually get used just forces a refresh\nplotNewDataBW(regenerateData(numPoints2 / 3), binWidth2, bandwidth, generate2);\n```\n\n\n## Automatic Bandwidth Selection\n\n::: smallest\n-   Because change in bandwidth leads to a continuous change in the density estimate, it is often easier to automatically pick a bandwidth!\n\n-   Silverman's 'rule-of-thumb' `bw.nrd0` :\n\n    $$ \n    \\begin{align*}\n      h = 0.9 * n^{-1/5} \\min(s, IQR/1.34)\n    \\end{align*}\n    $$\n\n    -   One of the most optimal bandwidth selectors **if** your data comes from a normal distribution\n    -   Default in `ggplot2` and `R`\n:::\n\n. . .\n\n::: smallest\n-   Sheather-Jones `bw.SJ`\n\n    -   More complicated bandwidth selector that \"would rather fit\" as the default\n\n    -   Less likely to give over-smoothed density graphs\n\n    -   `geom_density(bw = \"SJ\")` to use\n:::\n\n. . .\n\n::: smallest\n-   Other methods\n\n    -   Scott's plug in estimator `bw.nrd`: similar to Silverman's\n\n    -   `bw.ucv` and `bw.bcv`: cross validation based methods that are less useful for data visualization\n\n    -   `bw.SJ(<data>, method = \"dpi\")`: An easier to calculate Sheather-Jones estimate that gives worse results\n:::\n\n## Sheather-Jones Example\n\n::: panel-tabset\n### Useful\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/sj-use-case-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n### Not useful?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/sj-potentially-not-useful-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n\n## Kernel Density Estimates (Advanced) {.smaller}\n\n-   Density graphs are illustrations of Kernel Density Estimates:\n\n$$\n\\begin{align*}\n\\hat{f}_h(x) & = \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - x_i}{h}\\right)\n\\end{align*}\n$$\n\n-   $x_i$ is the $i^{th}$ data point\n\n-   $h$ is the bandwidth of the Kernel\n\n-   $K$ is the Kernel\n\n    -   $K$ can be a number of functions (see `kernel` option from `?density` or [Wikipedia](https://en.wikipedia.org/wiki/Kernel_(statistics)#Kernel_functions_in_common_use)) but is usually the Gaussian kernel: $K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$.\n    -   Choice of $K$ will give different looking density graphs, but choice of bandwidth is **a lot** more important than choice of Kernel. The Gaussian Kernel is by far the most used.\n    -   To see examples of Kernel choices, see this [shiny app](https://shinyserv.es/shiny/kde/) by Eduardo García-Portugués.\n\n::: {.footer style=\"font-size: 0.5em;\"}\nTo learn more, see [Chapter 2](https://bookdown.org/egarpor/NP-UC3M/kde-i-kde.html) of *Nonparametric Statistics* by Eduardo García-Portugués.\n:::\n\n## Cautions {.smaller}\n\n::: panel-tabset\n### Density Below 0\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nlong_tailed_data <- tibble(random_values = rlnorm(1000, -3, 1))\n```\n:::\n\n\n::: columns\n::: {.column width=\"49%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n  density(long_tailed_data$random_values, bw = \"SJ\"), \n  main = \"Density graph of positive numbers with density below 0\"\n) \nabline(v = 0, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-long-tailed-data-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(\n  density(long_tailed_data$random_values, bw = \"SJ\", from = 0),\n  main = \"Density graph of positive numbers with cut density\"\n)\nabline(v = 0, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/better-plot-long-tailed-data-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n:::\n\nggplot2 generally handles this for you by putting bounds at the range of your data, but it can occasionally skip this depending on how complicated your graph becomes.\n\n### Long Tailed Data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nlonger_tailed_data <- tibble(random_values = rlnorm(1000, -6, 5))\n```\n:::\n\n\n::: columns\n::: {.column width=\"49%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(longer_tailed_data, aes(x = random_values)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-longer-tailed-data-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(longer_tailed_data, aes(x = random_values)) +\n  geom_density() +\n  scale_x_continuous(trans = \"log\")\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-logged-longer-tailed-data-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n:::\n\nThis occurs in practice quite often!\n:::\n\n## 2D Density/Histograms {.smallest}\n\nPlayers that hit lots of home runs tend to strikeout and walk more.\n\n::: panel-tabset\n### Scatter plot\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_jitter(width = 0.3, height = 0.3, alpha = 0.1) +\n  geom_density_2d(alpha = 0.5) +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  )\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-2d-density-scatter-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n### 2D Bins\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_bin_2d(binwidth = c(2, 10)) +\n  geom_density_2d(alpha = 0.5) +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  ) +\n  scale_fill_viridis_c()\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-2d-bin-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n### 2D Density\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhome_runs |>\n  ggplot(aes(x = HR, y = SO + BB)) +\n  geom_density_2d_filled(show.legend = FALSE) +\n  geom_density_2d() +\n  labs(\n    x = \"Home runs per player per year\",\n    y = \"Strike outs and walks per player per year\"\n  )\n```\n\n::: {.cell-output-display}\n![](05-density-1_files/figure-revealjs/plot-2d-density-1.png){fig-align='center' width=3000}\n:::\n:::\n\n:::\n\n## Density Graphs Summary {.smaller}\n\nPros:\n\n-   **Visualize entire distribution**\n-   Mean, median, variance, outliers, support, skewness, normality etc.\n-   `plot(density(Batting$HR))` is usually the first thing I do when analyzing data\n\n. . .\n\nCons:\n\n-   Sensitive to bandwidth choices\n-   Harder to communicate to non-statisticians\n-   Difficult to build yourself (use libraries!)\n",
    "supporting": [
      "05-density-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}