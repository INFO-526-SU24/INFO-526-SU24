{
  "hash": "7066484f000d46c5ff034be5ac1cf4f6",
  "result": {
    "markdown": "---\ntitle: Visualizing density - II\nsubtitle: Lecture 6\ntitle-slide-attributes:\n  data-background-image: ../vizdata-bg.png\n  data-background-size: 800px, cover\n  data-slide-number: none\nformat: revealjs\nhighlight-style: a11y\nexecute:\n  code-link: true\neditor_options: \n  chunk_output_type: console\nrevealjs-plugins:\n  - code-mover\n---\n\n\n# Warm up\n\n## Announcements\n\n-   HW 02 is due February 14th\n-   Peer-review assignments will be announced before Wednesday (when peer-review will occur)\n\n## Warnings and messages\n\n-   You should suppress package loading and data loading messages with `message: false` as a chunk option\n\n-   You should also suppress warnings with `warning: false` **after** making sure you're ok with them, or update your code to eliminate warnings\n\n# HW 1 lessons learned\n\n## Highlights\n\n-   Review HW 1 issues, and show us you reviewed them by closing the issue.\n\n-   DO NOT hard code paths! Use the **`here`** package to help with relative paths, if you need.\n\n-   Make sure that all packages are installed/loaded. I suggest the `pacman` workflow we saw before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(\"pacman\")) \n  install.packages(\"pacman\")\n\npacman::p_load(package1, package2, ...)\npacman::p_load_gh(\"GitHubPackage1\")\n```\n:::\n\n\n## HW 1 lessons learned cont...\n\n::: incremental\n1.  **Start early**. No late work exceptions will be made in the future\n2.  **Ask your peers**. I have been monopolized by a few individuals, which is not fair to the rest.\n    1.  Peers will likely have the answer\n    2.  Peers will likely get to the question before I will.\n3.  **Ask descriptive questions**. See [this page](https://datavizaz.org/course-support.html#how-to-ask-for-help) on asking effective questions.\n4.  **Please respect my work hours**. I will no longer reply to messages after 5pm on work days and at all on weekends.\n:::\n\n## Setup {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(ggthemes)\nlibrary(gt)\n\n# set theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 12))\n\n# set width of code output\noptions(width = 65)\n\n# set figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 7,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  fig.align = \"center\",\n  dpi = 300\n)\n```\n:::\n\n\n# Densities\n\n## Distributions and Motivating Example\n\n::: columns\n::: {.column .smallest width=\"49%\"}\nThere are many properties of a distribution of values\n\n-   **Center**: Mean, Median, Modes\n-   **Spread**: Variance, Range (Support), Interquartile range\n-   **Shape**: Skewness, Kurtosis, Quantiles\n-   Any statistic you can think of\n\nUltimately when analyzing data, the distribution is important to know how to proceed:\n\n-   Parametric tests\n-   Erratic Data\n-   Outliers\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/density-example-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column .smallest width=\"49%\"}\n-   Baseball! A home run in baseball occurs when a player hits a fair ball outside of the playing field.\n-   Baseball is a game with a long rich history, but home runs have always been an integral part of it. By examining the distribution of home runs year-by-year we may be able to see the effect of various rule changes or events.\n\n::: {style=\"text-align: center\"}\n<iframe src=\"https://giphy.com/embed/AFX2Yx807TCX4YuLP4\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen>\n\n</iframe>\n\n<p><a href=\"https://giphy.com/gifs/mlb-world-series-2018-AFX2Yx807TCX4YuLP4\">via GIPHY</a></p>\n:::\n:::\n:::\n\n## Data {.smaller}\n\n<div>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(Lahman)\n\nhome_runs <- Batting |> \n  filter(\n    G >= 100 | # We want to see how many home runs players that played most of the season hit\n    (G >= 40 & yearID == 2020) | # COVID-shortened season\n    (G >= 70 & yearID == 1994), # Strike-shortened season\n    yearID > 1920, # Beginning of live-ball era\n    lgID %in% c(\"AL\", \"NL\")\n  ) # Most common leagues\n```\n:::\n\n\nOur dataset comes from the R package `Lahman`. Each row in the data frame is the hitting stats of a player for a given year. Today we will use the following columns:\n\n| Variable | Description                                                                        |\n|------------------------|-----------------------------------------------|\n| `yearID` | The year for the statistics                                                        |\n| `HR`     | The number of home runs a player hit in a given year                               |\n| `G`      | Number of games played; there are 162 games in a baseball season (154 before 1961) |\n\nIn particular we are interested in the distribution of home runs per year!\n\n</div>\n\n## Important notes from last time {.smaller}\n\n::: columns\n::: {.column width=\"49%\"}\nAlthough density graphs are very useful and can display lots of information, they can be sensitive to bandwidth.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/bandwidth-sensitivity-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\nIt was not clear how to properly determine if two distributions were significantly different.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/similar-distributions-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n:::\n\n## Cumulative Distribution Functions (CDF) {.smaller .incremental}\n\n::: incremental\n-   For a random variable $X$, the CDF describes the probability that $X$ is below a certain value:\n\n    -   Between 0 and 1 (like all probabilities)\n    -   Non-decreasing\n    -   Derivative is the PDF, i.e. the larger the PDF the faster the CDF is increasing.\n    -   Example: If $X \\sim \\textsf{Normal}(0, 1)$\n:::\n\n. . .\n\n$$\n\\begin{align*}\n  F_X(x) & = P(X \\leq x) \\\\\n  F_x(-\\infty) & = 0 \\\\ \n  F_x(-1) & = 0.1587 \\\\ \n  F_x(0) & = 1/2 \\\\ \n  F_x(1) & =  0.8413 \\\\ \n  F_x(\\infty) & = 1\n\\end{align*}\n$$\n\n## Empirical CDF (ECDF) {.smaller}\n\n::: incremental\n-   The empirical CDF of data is the proportion of data below a certain value:\n    -   Between 0 and 1 (like all probabilities)\n    -   Non-decreasing\n    -   Increases at every value of observed data (step function)\n    -   Example: `X = c(0, 1, 2, 2, 3, 3.5, 4)`\n:::\n\n. . .\n\n$$\n\\begin{align*}\n  F_n(t) & = \\frac{1}{n} \\sum_{i=1}^n \\begin{cases} 1 & x_i \\leq t \\\\ 0 & \\text{otherwise} \\end{cases} \\\\\n  F_7(-1) & = 0 \\\\\n  F_7(0) & = 1/7 \\\\ \n  F_7(2.5) & = 4/7 \\\\\n  F_7(4) & = 1 \\\\\n  F_7(5) & = 1\n\\end{align*}\n$$\n\n## Empirical CDFs in R {.smaller}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnew_example_data <- c(\n  rnorm(n = 200, mean = -1, sd = 0.5),\n  rnorm(n = 400, mean = 2, sd = 0.75)\n)\nmix_ecdf <- ecdf(new_example_data)\n```\n:::\n\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table id=\"ecdf-table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Function Call </th>\n   <th style=\"text-align:right;\"> Probability less than value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> mix_ecdf(-3) </td>\n   <td style=\"text-align:right;\"> 0.0000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mix_ecdf(-1) </td>\n   <td style=\"text-align:right;\"> 0.1533 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mix_ecdf(0) </td>\n   <td style=\"text-align:right;\"> 0.3333 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mix_ecdf(2) </td>\n   <td style=\"text-align:right;\"> 0.6750 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mix_ecdf(5) </td>\n   <td style=\"text-align:right;\"> 1.0000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"45%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/ecdf-plot-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n:::\n\n## Kolmogorov-Smirnov Test (Two-sample) {.smaller}\n\n::: incremental\n-   **Theorem**: If two random quantities have equal CDF's they have the exact same distribution.\n-   The *Kolmogorov-Smirnov Test* finds the maximum difference between two empirical CDF's and outputs a test statistic based on the sample sizes.\n-   The test is best used with continuous data as it is approximate in the case of discrete data, but it is good enough for our purposes.\n-   Conditions to perform the test (which we somewhat violate):\n    -   Values must be i.i.d. within their respective distributions\n    -   The two distributions being tested must be independent\n:::\n\n## Comparing Distributions 1 {.smaller}\n\n::: panel-tabset\n### Output\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\n# Closest 4 years\nHRearly2010s <- home_runs |> \n  filter(yearID %in% 2011:2014)\n\n# Years up to COVID season\nHRlate2010s <- home_runs |> \n  filter(yearID %in% 2016:2019) \n\nks.test(HRearly2010s$HR, HRlate2010s$HR)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HRearly2010s$HR and HRlate2010s$HR\nD = 0.16691, p-value = 6.463e-12\nalternative hypothesis: two-sided\n```\n:::\n:::\n\n:::\n\n::: {.column .move-code width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_ks_df <- function(dat1, dat2) {\n  # Make ECDF of each set of data\n  ecdf1 <- ecdf(dat1)\n  ecdf2 <- ecdf(dat2)\n  # Calculate the absolute difference between the 2 ECDFs on the support\n  grid_points <- seq(0, max(c(dat1, dat2)), length.out=1000)\n  differences <- abs(ecdf1(grid_points) - ecdf2(grid_points))\n  # Get the KS statistic and where it occurs\n  ks_stat <- max(differences)\n  first_max_location <- grid_points[which.max(differences)]\n  # Return tibble to help with plotting\n  tibble(\n    x = first_max_location,\n    xend = first_max_location,\n    y = ecdf1(first_max_location),\n    yend = ecdf2(first_max_location)\n  )\n}\n\nks_stat_2010s <- get_ks_df(HRearly2010s$HR, HRlate2010s$HR)\n\nggplot(rbind(HRearly2010s, HRlate2010s), aes(HR, color = factor(yearID < 2015))) +\n  stat_ecdf(geom = \"step\") +\n  geom_segment(\n    data = ks_stat_2010s,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    color = \"black\",\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Homeruns per player per year\",\n    y = \"Empirical CDF\",\n    title = \"Empirical CDFs of player home runs per year in years 2011-2019 \",\n    subtitle = \"Dashed line is the Kolmogorov-Smirnov Statistic\"\n  ) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/compare-dists-1-2-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n:::\n\nMajor League Baseball was accused of replacing the standard baseballs with \"juiced\" baseballs (easier to hit home runs) secretly in the middle of 2015. Is there credence to this claim?\n\n### Code\n:::\n\n## Comparing Distributions 2 {.smaller}\n\n::: panel-tabset\n### Output\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nHR2005 <- home_runs |>\n  filter(yearID == 2005)\nHR2006 <- home_runs |> \n  filter(yearID == 2006)\n\nks.test(HR2005$HR, HR2006$HR)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HR2005$HR and HR2006$HR\nD = 0.073827, p-value = 0.503\nalternative hypothesis: two-sided\n```\n:::\n:::\n\n:::\n\n::: {.column .move-code width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nks_stat_0506 <- get_ks_df(HR2005$HR, HR2006$HR)\n\nggplot(rbind(HR2005, HR2006), aes(HR, color = factor(yearID))) +\n  stat_ecdf(geom = \"step\") +\n  geom_segment(\n    data = ks_stat_0506,\n    aes(\n      x = x,\n      y = y,\n      xend = xend,\n      yend = yend\n    ),\n    color = \"black\",\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Homeruns per player per year\",\n    y = \"Empirical CDF\",\n    title = \"Empirical CDFs of player home runs per year in years 2005 and 2006 \",\n    subtitle = \"Dashed line is the Kolmogorov-Smirnov Statistic\",\n    color = \"Year\"\n  ) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/compare-dists-2-2-1.png){fig-align='center' width=2100}\n:::\n:::\n\n:::\n:::\n\n-   2005 and 2006 are similar years in terms of home runs, so the Kolmogorov-Smirnov test does not reject.\n\n### Code\n:::\n\n## Using the Kolmogorov-Smirnov statistic for visualization\n\n-   Our earlier motivation was to compare the distribution of homeruns over time to see if rule changes made a difference.\n-   We can't use a ridge or violin plot with all 100 years; it would be too cramped.\n-   What if we used the KS statistic to compare all pairs of years and emulated a correlation matrix?\n\n## Building the Matrix\n\n::: smallest\n\n::: {.cell layout-align=\"center\" hash='06-density-2_cache/revealjs/build-ks-matrix_a5ecdc1f3a4950184d0029ea05d3939c'}\n\n```{.r .cell-code}\nks_matrix <- tribble(~year1, ~year2, ~ks_stat, ~p_value)\nall_years <- unique(home_runs$yearID)\n\n# Save some memory\nhome_runs_to_search <- home_runs |> select(yearID, HR)\n\noptions(warn = -1) # Turn off ks.test warning\n\nfor (year1 in all_years) {\n  year1HR <- home_runs_to_search |> filter(yearID == year1)\n  for (year2 in min(all_years):year1) { # Only do half since the test is symmetric\n    if (year1 == year2) {\n      next\n    }\n    year2HR <- home_runs_to_search |> filter(yearID == year2)\n\n    test <- ks.test(\n      year1HR$HR,\n      year2HR$HR\n    )\n\n    ks_matrix <- ks_matrix |>\n      add_row(\n        year1 = year1,\n        year2 = year2,\n        ks_stat = test$statistic,\n        p_value = test$p.value\n      )\n  }\n}\n\nks_matrix <- bind_rows(\n  ks_matrix,\n  ks_matrix |> mutate(\n    tmp_year1 = year1,\n    year1 = year2,\n    year2 = tmp_year1\n  ) |> select(-tmp_year1)\n)\n\noptions(warn = 0)\n```\n:::\n\n:::\n\n## Visualizing the Matrix (p-values)\n\n::: panel-tabset\n### Plot {.move-code .smallest}\n\n::: columns\n::: {.column width=\"69%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/visualize-ks-matrix-1.png){fig-align='center' width=1950}\n:::\n:::\n\n:::\n\n::: {.column width=\"29%\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\nHR2016 <- home_runs |> \n  filter(yearID == 2016)\n\nks.test(HR2005$HR, HR2016$HR)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAsymptotic two-sample Kolmogorov-Smirnov test\n\ndata:  HR2005$HR and HR2016$HR\nD = 0.14405, p-value = 0.01089\nalternative hypothesis: two-sided\n```\n:::\n:::\n\n\n-   There seems to be some patterns in our matrix, but there's a problem...\n:::\n:::\n\n### Code {.smallest}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nks_matrix |>\n  mutate(signif = cut(\n    p_value,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(\n    x = year1,\n    y = year2,\n    fill = factor(signif)\n  )) +\n  geom_tile() +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(\n    title = \"Unadjusted p-values matrix\",\n    fill = \"Significance\",\n    x = \"Year\",\n    y = \"Year\"\n  ) +\n  coord_fixed() +\n  annotate(\n    \"rect\",\n    xmin = c(2004.5, 2015.5),\n    ymin = c(2015.5, 2004.5),\n    xmax = c(2005.5, 2016.5),\n    ymax = c(2016.5, 2005.5),\n    color = \"#0000FFaa\",\n    alpha = 0,\n    size = 1\n  )\n```\n:::\n\n:::\n\n## Multiple Testing\n\n::: {.smallest .incremental}\n-   When performing multiple hypothesis tests, we typically want to control the *Family Wise Error Rate*: the probability we make at least 1 Type I error (a false rejection).\n-   Newer methods focus more on controlling the *False Discovery Rate*: the probability that any particular rejected null hypothesis is actually a false positive.\n-   Both require adjusting p-values which is built in to `R` (`?p.adjust`).\n    -   `holm`, `hochberg` and `hommel` control for Family Wise Error Rate\n        -   `bonferroni` also controls for this, but is very conservative\n    -   `fdr` and `BY` methods control for False Discovery Rate\n:::\n\n. . .\n\n::: smallest\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Let's try all the adjustments and see how they change our visualization\nhalf_matrix <- ks_matrix |>\n  filter(year1 < year2) |>\n  mutate(\n    p_holm = p.adjust(p_value, \"holm\"),\n    p_hochberg = p.adjust(p_value, \"hochberg\"),\n    p_hommel = p.adjust(p_value, \"hommel\"),\n    p_bonferroni = p.adjust(p_value, \"bonferroni\"),\n    p_fdr = p.adjust(p_value, \"fdr\"),\n    p_BY = p.adjust(p_value, \"BY\")\n  )\n\nother_half <- half_matrix |>\n  mutate(\n    tmp_year1 = year1,\n    year1 = year2,\n    year2 = tmp_year1\n  ) |>\n  select(-tmp_year1)\n\nks_matrix <- bind_rows(half_matrix, other_half)\n```\n:::\n\n:::\n\n## Visualizing the Matrix (Corrections) {.smallest}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/plot-adjustments-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\nControlling for the Family Wise Error Rate got rid of a lot of our interesting patterns. We don't mind some false positives so we choose the `BY` adjustment as it controls False Discovery Rate but is a bit more conservative than `FDR`.\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nks_matrix |>\n  pivot_longer(\n    c(\n      \"p_holm\",\n      \"p_hochberg\",\n      \"p_hommel\",\n      \"p_bonferroni\",\n      \"p_fdr\",\n      \"p_BY\"\n    ),\n    names_to = \"adjustment\",\n    values_to = \"adjusted_p\"\n  ) |>\n  mutate(signif = cut(\n    adjusted_p,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(\n    x = year1,\n    y = year2,\n    fill = factor(signif)\n  )) +\n  geom_tile() +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(\n    x = \"Year\",\n    y = \"Year\",\n    fill = \"Significance\"\n  ) +\n  facet_wrap(~adjustment) +\n  coord_fixed() +\n  theme(\n    axis.text.x = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\n```\n:::\n\n:::\n\n## Pre-Integration {.smallest}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/by-adjustment-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmat_BY <-\n  ks_matrix |>\n  mutate(signif = cut(\n    p_BY,\n    breaks = c(0, 0.001, 0.01, 0.05, 0.1, 1.001),\n    labels = c(\"<0.001\", \"<0.01\", \"<0.05\", \"<0.1\", \"<1\"),\n    include.lowest = T,\n  )) |>\n  ggplot(aes(x = year1,\n             y = year2)) +\n  geom_tile(aes(fill = factor(signif))) +\n  scale_x_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_y_continuous(breaks = 1920 + seq(0, 10) * 10) +\n  scale_fill_manual(values = c(colorspace::heat_hcl(4), \"#AAAAAA\")) +\n  labs(title = \"BY adjusted p-values matrix\",\n       fill = \"Significance\",\n       x = \"Year\",\n       y = \"Year\") +\n  coord_fixed()\n\ndescription <- \"Major League Baseball was segregated by race until Jackie Robinson broke the color barrier in 1947.The talent level of the league changed rapidly, including the overall distribution of home runs.\" |> \n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = 1920,\n    ymin = 1920,\n    xmax = 1947,\n    ymax = 1947,\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1980,\n    y = 1980,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )\n```\n:::\n\n:::\n\n## World War II {.smallest}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/ww2-annotate-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescription <-\n  \"During World War II, many baseball players fought overseas,making for an atypical number of home runs during these years.\" |> \n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 1941),\n    ymin = c(1941, 1920),\n    xmax = c(2022, 1945),\n    ymax = c(1945, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1990,\n    y = 1990,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )\n```\n:::\n\n:::\n\n## Shortened Seasons {.smallest}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/shorter-season-annotate-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescription <-\n  \"In 1994 less homeruns were hit due to the strike-shorted season. Similarly, COVID in 2020 called for a shorter season.\" |>\n  str_wrap(width=40)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 2019, 1920, 1993),\n    ymin = c(2019, 1920, 1993, 1920),\n    xmax = c(2022, 2021, 2022, 1995),\n    ymax = c(2021, 2022, 1995, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 1950,\n    y = 1950,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )\n```\n:::\n\n:::\n\n## Year of the Pitcher {.smallest}\n\n::: panel-tabset\n### Plot {.move-code}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-density-2_files/figure-revealjs/yotp-annotate-1.png){fig-align='center' width=2100}\n:::\n:::\n\n\n### Code\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndescription <-\n  \"1968 is known as the Year of the Pitcher, when pitchers dominated the league causing less homeruns. The next year, the pitcher's mound was made smaller to give \\npitchers a smaller advantage.\" |>\n  str_wrap(width = 30)\n\nmat_BY +\n  annotate(\n    \"rect\",\n    xmin = c(1920, 1967),\n    ymin = c(1967, 1920),\n    xmax = c(2022, 1969),\n    ymax = c(1969, 2022),\n    color = \"#0000FFaa\",\n    alpha = 0\n  ) +\n  annotate(\n    \"label\",\n    x = 2000,\n    y = 1950,\n    label = description,\n    alpha = 0.9,\n    size = 3\n  )\n```\n:::\n\n:::\n\n## Summary\n\n-   The Empirical CDF is a very useful tool in statistics, for both analysis and visualization.\n-   The Kolmogorov-Smirnov Test is a good way to test if two distributions of values are different.\n    -   However, be careful as it is only an approximate test with discrete values.\n    -   Furthermore, be sure to use multiple testing corrections if testing many different distributions.\n-   Baseball is interesting! (you may disagree on this one)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}